{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262fa2a0-96a0-4fbc-ba14-1c02937eabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load and preprocess data\n",
    "\n",
    "def load_and_preprocess(filepath):\n",
    "    # Columns to drop\n",
    "    drop_cols = [\"sourcePayloadAsBase64\", \"sourcePayloadAsUTF\", \n",
    "                 \"destinationPayloadAsBase64\", \"destinationPayloadAsUTF\"]\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    datetime_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in datetime_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], format='%m/%d/%Y %H:%M')\n",
    "            df[col] = df[col].astype(np.int64) // 10**9\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, le.fit_transform(y)\n",
    "\n",
    "\n",
    "# Quantum circuit for angle embedding\n",
    "def quantum_circuit(features, n_qubits):\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def circuit(x):\n",
    "        # Angle embedding\n",
    "        qml.AngleEmbedding(x, wires=range(n_qubits))\n",
    "        \n",
    "        # Entangling layers\n",
    "        for i in range(n_qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "            \n",
    "        # Measure all qubits\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    \n",
    "    return circuit(features)\n",
    "\n",
    "# Quantum feature mapping\n",
    "def quantum_feature_mapping(X, n_qubits):\n",
    "    X_quantum = []\n",
    "    for sample in tqdm(X, desc=\"Quantum Feature Mapping\"):\n",
    "        # Pad or truncate features to match n_qubits\n",
    "        features = sample[:n_qubits]\n",
    "        quantum_features = quantum_circuit(features, n_qubits)\n",
    "        X_quantum.append(quantum_features)\n",
    "    return np.array(X_quantum)\n",
    "\n",
    "def evaluate_classifiers(X_train, X_test, y_train, y_test, classifiers):\n",
    "    results = []\n",
    "    \n",
    "    for name, clf in tqdm(classifiers.items(), desc=\"Training Classifiers\"):\n",
    "        # Training\n",
    "        start_fit = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        fit_time = time.time() - start_fit\n",
    "        \n",
    "        # Prediction\n",
    "        start_predict = time.time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        predict_time = time.time() - start_predict\n",
    "        \n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            'Classifier': name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1': f1_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_pred),\n",
    "            'Kappa': cohen_kappa_score(y_test, y_pred),\n",
    "            'Fit Time': fit_time,\n",
    "            'Predict Time': predict_time\n",
    "        }\n",
    "        results.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf077f45-d3b1-4b1f-a67e-a94de1207bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "1    255170\n",
      "0     20358\n",
      "Name: count, dtype: int64\n",
      "Balanced class distribution:\n",
      "0    20358\n",
      "1    20358\n",
      "Name: count, dtype: int64\n",
      "Classical ML Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Classifiers: 100%|██████████████████████████████████████████████████████████████| 9/9 [01:00<00:00,  6.72s/it]\n",
      "Quantum Feature Mapping: 100%|███████████████████████████████████████████████████| 32572/32572 [06:50<00:00, 79.37it/s]\n",
      "Quantum Feature Mapping: 100%|█████████████████████████████████████████████████████| 8144/8144 [02:09<00:00, 62.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum ML Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Classifiers: 100%|██████████████████████████████████████████████████████████████| 9/9 [01:21<00:00,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classical ML Results:\n",
      "            Classifier  Accuracy  Precision    Recall        F1   ROC AUC  \\\n",
      "0          Extra Trees  0.999140   0.999026  0.999269  0.999148  0.999139   \n",
      "1              XGBoost  0.999263   0.999513  0.999026  0.999269  0.999265   \n",
      "2        Random Forest  0.999263   1.000000  0.998539  0.999269  0.999269   \n",
      "3             CatBoost  0.999140   0.999756  0.998539  0.999147  0.999146   \n",
      "4             AdaBoost  0.997544   0.998050  0.997077  0.997563  0.997548   \n",
      "5    Gradient Boosting  0.999140   1.000000  0.998295  0.999147  0.999148   \n",
      "6  Logistic Regression  0.978757   0.980689  0.977107  0.978895  0.978771   \n",
      "7                  KNN  0.995825   0.994415  0.997321  0.995866  0.995813   \n",
      "8        Decision Tree  0.998772   0.999025  0.998539  0.998782  0.998774   \n",
      "\n",
      "      Kappa   Fit Time  Predict Time  \n",
      "0  0.998281   2.708005      0.132425  \n",
      "1  0.998526   1.208272      0.026608  \n",
      "2  0.998526   5.281624      0.087290  \n",
      "3  0.998281  16.074282      0.077011  \n",
      "4  0.995088   3.650978      0.711832  \n",
      "5  0.998281  23.382267      0.014031  \n",
      "6  0.957513   0.095328      0.001001  \n",
      "7  0.991650   0.005715      4.263623  \n",
      "8  0.997544   1.730273      0.021134  \n",
      "\n",
      "Quantum ML Results:\n",
      "            Classifier  Accuracy  Precision    Recall        F1   ROC AUC  \\\n",
      "0          Extra Trees  0.995457   0.994411  0.996590  0.995499  0.995447   \n",
      "1              XGBoost  0.993492   0.990559  0.996590  0.993566  0.993466   \n",
      "2        Random Forest  0.995702   0.994173  0.997321  0.995745  0.995689   \n",
      "3             CatBoost  0.993615   0.990561  0.996834  0.993688  0.993588   \n",
      "4             AdaBoost  0.961076   0.975646  0.946420  0.960811  0.961199   \n",
      "5    Gradient Boosting  0.990791   0.988369  0.993424  0.990890  0.990769   \n",
      "6  Logistic Regression  0.841356   0.835960  0.852655  0.844225  0.841260   \n",
      "7                  KNN  0.992755   0.988886  0.996834  0.992844  0.992721   \n",
      "8        Decision Tree  0.994229   0.993916  0.994642  0.994279  0.994225   \n",
      "\n",
      "      Kappa   Fit Time  Predict Time  \n",
      "0  0.990913  11.553374      1.554006  \n",
      "1  0.986983   7.496492      0.171614  \n",
      "2  0.991404   5.347909      0.107309  \n",
      "3  0.987228  45.586211      0.037549  \n",
      "4  0.922165   1.863148      0.053631  \n",
      "5  0.981579   5.912874      0.014533  \n",
      "6  0.682636   0.086516      0.001042  \n",
      "7  0.985509   0.048647      0.991722  \n",
      "8  0.988457   0.126461      0.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_preprocess('TestbedSunJun13Flows.csv')\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    # Add this after X, y = load_and_preprocess_data('TestbedSunJun13Flows.csv')\n",
    "    # and before train_test_split\n",
    "    \n",
    "    print(\"Original class distribution:\")\n",
    "    print(pd.Series(y).value_counts())\n",
    "    \n",
    "    # Perform undersampling\n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_balanced, y_balanced = undersampler.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Balanced class distribution:\")\n",
    "    print(pd.Series(y_balanced).value_counts())\n",
    "    \n",
    "    # Update your X and y variables\n",
    "    X = X_balanced\n",
    "    y = y_balanced\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = {\n",
    "        'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "        'XGBoost': xgb.XGBClassifier(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostClassifier(random_state=42, verbose=False),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=42),    \n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Classical ML evaluation\n",
    "    print(\"Classical ML Evaluation:\")\n",
    "    classical_results = evaluate_classifiers(X_train, X_test, y_train, y_test, classifiers)\n",
    "    \n",
    "    # Quantum Feature Mapping\n",
    "    n_qubits = 8  # Adjust based on your quantum computer capacity\n",
    "    X_train_quantum = quantum_feature_mapping(X_train, n_qubits)\n",
    "    X_test_quantum = quantum_feature_mapping(X_test, n_qubits)\n",
    "    \n",
    "    # Quantum ML evaluation\n",
    "    print(\"\\nQuantum ML Evaluation:\")\n",
    "    quantum_results = evaluate_classifiers(X_train_quantum, X_test_quantum, y_train, y_test, classifiers)\n",
    "\n",
    "    results_df = pd.DataFrame(quantum_results)\n",
    "    results_df1 = pd.DataFrame(classical_results)\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv('5th dataset angle embedding_quantum.csv', index=False)\n",
    "    results_df1.to_csv('5th dataset angle embedding_classical.csv', index=False)\n",
    "    # Display results\n",
    "    print(\"\\nClassical ML Results:\")\n",
    "    print(classical_results)\n",
    "    print(\"\\nQuantum ML Results:\")\n",
    "    print(quantum_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307f291-02ab-48c3-b379-06d1a8d81ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
