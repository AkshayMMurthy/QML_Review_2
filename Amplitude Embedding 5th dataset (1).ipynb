{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f1b99d9-ce2e-471a-80cd-e163c3124442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import pennylane as qml\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    # Columns to drop\n",
    "    drop_cols = [\"sourcePayloadAsBase64\", \"sourcePayloadAsUTF\", \n",
    "                 \"destinationPayloadAsBase64\", \"destinationPayloadAsUTF\"]\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    datetime_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in datetime_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], format='%m/%d/%Y %H:%M')\n",
    "            df[col] = df[col].astype(np.int64) // 10**9\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, le.fit_transform(y)\n",
    "\n",
    "# Quantum amplitude embedding circuit\n",
    "def create_quantum_circuit(n_qubits):\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def quantum_circuit(inputs):\n",
    "        # Amplitude embedding\n",
    "        qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True)\n",
    "        \n",
    "        # Rotation layers\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(np.pi/2, wires=i)\n",
    "            qml.RZ(np.pi/4, wires=i)\n",
    "        \n",
    "        # Entangling layers\n",
    "        for i in range(n_qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "        \n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    \n",
    "    return quantum_circuit\n",
    "\n",
    "# Quantum feature extraction\n",
    "def quantum_feature_extraction(X, n_qubits):\n",
    "    quantum_circuit = create_quantum_circuit(n_qubits)\n",
    "    quantum_features = []\n",
    "    \n",
    "    for sample in tqdm(X, desc=\"Quantum Feature Extraction\"):\n",
    "        # Calculate required padding\n",
    "        target_size = 2**n_qubits\n",
    "        # Normalize and pad the sample to match required qubit size\n",
    "        normalized_sample = sample / np.linalg.norm(sample)\n",
    "        padded_sample = np.zeros(target_size)\n",
    "        padded_sample[:len(normalized_sample)] = normalized_sample\n",
    "        # Renormalize after padding\n",
    "        padded_sample = padded_sample / np.linalg.norm(padded_sample)\n",
    "        quantum_features.append(quantum_circuit(padded_sample))\n",
    "    \n",
    "    return np.array(quantum_features)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_classifier(clf, X_train, X_test, y_train, y_test, name):\n",
    "    start_fit = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    fit_time = time.time() - start_fit\n",
    "    \n",
    "    start_pred = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    pred_time = time.time() - start_pred\n",
    "    \n",
    "    # Modified metrics calculation for multi-class\n",
    "    metrics = {\n",
    "        'Classifier': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1': f1_score(y_test, y_pred, average='weighted'),\n",
    "        #'ROC AUC': roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]) if len(np.unique(y)) == 2 else roc_auc_score(y_test, clf.predict_proba(X_test), multi_class='ovr', average='weighted'),\n",
    "        'Kappa': cohen_kappa_score(y_test, y_pred),\n",
    "        'Fit Time': fit_time,\n",
    "        'Predict Time': pred_time\n",
    "    }\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3173190c-b981-467c-887d-f79e708a2410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "1    255170\n",
      "0     20358\n",
      "Name: count, dtype: int64\n",
      "Balanced class distribution:\n",
      "0    20358\n",
      "1    20358\n",
      "Name: count, dtype: int64\n",
      "Evaluating Classical ML Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:43<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 qubits for quantum circuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantum Feature Extraction: 100%|███████████████████████████████████████████████| 32572/32572 [04:14<00:00, 127.95it/s]\n",
      "Quantum Feature Extraction: 100%|█████████████████████████████████████████████████| 8144/8144 [01:03<00:00, 128.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Quantum ML Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:48<00:00,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "                   Classifier  Accuracy  Precision   Recall       F1    Kappa  Fit Time  Predict Time\n",
      "        Classical Extra Trees  0.999140   0.999140 0.999140 0.999140 0.998281  1.269210      0.096744\n",
      "            Classical XGBoost  0.999263   0.999263 0.999263 0.999263 0.998526  0.294805      0.015619\n",
      "      Classical Random Forest  0.999263   0.999264 0.999263 0.999263 0.998526  2.354936      0.047309\n",
      "           Classical CatBoost  0.999140   0.999141 0.999140 0.999140 0.998281 28.756250      0.081601\n",
      "           Classical AdaBoost  0.997544   0.997545 0.997544 0.997544 0.995088  1.799892      0.033443\n",
      "  Classical Gradient Boosting  0.999140   0.999142 0.999140 0.999140 0.998281  7.181824      0.000000\n",
      "Classical Logistic Regression  0.978757   0.978765 0.978757 0.978758 0.957513  0.099254      0.015662\n",
      "                Classical KNN  0.995825   0.995829 0.995825 0.995825 0.991650  0.016457      1.333194\n",
      "      Classical Decision Tree  0.998772   0.998772 0.998772 0.998772 0.997544  0.133529      0.000000\n",
      "          Quantum Extra Trees  0.997913   0.997914 0.997913 0.997913 0.995825  1.343749      0.093751\n",
      "              Quantum XGBoost  0.995088   0.995091 0.995088 0.995088 0.990176  0.265613      0.015624\n",
      "        Quantum Random Forest  0.997176   0.997177 0.997176 0.997176 0.994351  7.844202      0.078127\n",
      "             Quantum CatBoost  0.993001   0.993007 0.993001 0.993001 0.986001 28.179476      0.015628\n",
      "             Quantum AdaBoost  0.921169   0.921277 0.921169 0.921169 0.842347  1.703127      0.031253\n",
      "    Quantum Gradient Boosting  0.976179   0.976214 0.976179 0.976177 0.952351  7.624994      0.015626\n",
      "  Quantum Logistic Regression  0.855354   0.856086 0.855354 0.855311 0.710793  0.031239      0.000000\n",
      "                  Quantum KNN  0.991528   0.991528 0.991528 0.991528 0.983054  0.031248      0.500006\n",
      "        Quantum Decision Tree  0.993492   0.993501 0.993492 0.993492 0.986984  0.249995      0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load and preprocess data\n",
    "    X, y = load_and_preprocess_data('TestbedSunJun13Flows.csv')\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    # Add this after X, y = load_and_preprocess_data('TestbedSunJun13Flows.csv')\n",
    "    # and before train_test_split\n",
    "    \n",
    "    print(\"Original class distribution:\")\n",
    "    print(pd.Series(y).value_counts())\n",
    "    \n",
    "    # Perform undersampling\n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_balanced, y_balanced = undersampler.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Balanced class distribution:\")\n",
    "    print(pd.Series(y_balanced).value_counts())\n",
    "    \n",
    "    # Update your X and y variables\n",
    "    X = X_balanced\n",
    "    y = y_balanced\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define classifiers\n",
    "    classifiers = [\n",
    "        ('Extra Trees', ExtraTreesClassifier(n_estimators=100, random_state=42)),\n",
    "        ('XGBoost', xgb.XGBClassifier(random_state=42)),\n",
    "        ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('CatBoost', CatBoostClassifier(random_state=42, verbose=False)),\n",
    "        ('AdaBoost', AdaBoostClassifier(random_state=42)),    \n",
    "        ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "        ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('Decision Tree', DecisionTreeClassifier(random_state=42))\n",
    "        \n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Classical ML evaluation\n",
    "    classical_results = []\n",
    "    print(\"Evaluating Classical ML Models...\")\n",
    "    for name, clf in tqdm(classifiers):\n",
    "        metrics = evaluate_classifier(clf, X_train, X_test, y_train, y_test, f\"Classical {name}\")\n",
    "        classical_results.append(metrics)\n",
    "    \n",
    "    # Quantum feature extraction\n",
    "     # Calculate minimum required qubits\n",
    "    n_features = X.shape[1]\n",
    "    n_qubits = int(np.ceil(np.log2(n_features)))\n",
    "    \n",
    "    \n",
    "    n_qubits = int(np.ceil(np.log2(X.shape[1])))\n",
    "    print(f\"Using {n_qubits} qubits for quantum circuit\")\n",
    "    \n",
    "    X_train_quantum = quantum_feature_extraction(X_train, n_qubits)\n",
    "    X_test_quantum = quantum_feature_extraction(X_test, n_qubits)\n",
    "    \n",
    "    # Quantum ML evaluation\n",
    "    quantum_results = []\n",
    "    print(\"Evaluating Quantum ML Models...\")\n",
    "    for name, clf in tqdm(classifiers):\n",
    "        metrics = evaluate_classifier(clf, X_train_quantum, X_test_quantum, y_train, y_test, f\"Quantum {name}\")\n",
    "        quantum_results.append(metrics)\n",
    "    \n",
    "    # Combine and display results\n",
    "    all_results = pd.DataFrame(classical_results + quantum_results)\n",
    "    print(\"\\nResults:\")\n",
    "    print(all_results.to_string(index=False))\n",
    "    \n",
    "    \n",
    "    # Save results\n",
    "    # Save results\n",
    "    all_results.to_csv('5th dataset amplitude.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61c7c7-c3b3-4be2-b44a-d9ef5f450d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
