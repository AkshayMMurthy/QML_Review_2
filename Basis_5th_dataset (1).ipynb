{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fa8f1de-3bdc-4095-9329-fa5161dee0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "def load_and_preprocess(filepath):\n",
    "    # Columns to drop\n",
    "    drop_cols = [\"sourcePayloadAsBase64\", \"sourcePayloadAsUTF\", \n",
    "                 \"destinationPayloadAsBase64\", \"destinationPayloadAsUTF\"]\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    \n",
    "    # Convert datetime columns\n",
    "    datetime_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in datetime_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], format='%m/%d/%Y %H:%M')\n",
    "            df[col] = df[col].astype(np.int64) // 10**9\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, le.fit_transform(y)\n",
    "\n",
    "def quantum_circuit(features, n_qubits):\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def circuit(x):\n",
    "        # Basis embedding - converts classical bits to quantum states\n",
    "        qml.BasisEmbedding(x, wires=range(n_qubits))\n",
    "        \n",
    "        # Apply quantum operations\n",
    "        for i in range(n_qubits-1):\n",
    "            qml.CNOT(wires=[i, i+1])\n",
    "        \n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(np.pi/4, wires=i)\n",
    "            \n",
    "        # Measure in computational basis\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    \n",
    "    return circuit(features)\n",
    "\n",
    "def prepare_basis_features(X, n_qubits):\n",
    "    # Convert continuous features to binary representation for basis embedding\n",
    "    binary_features = []\n",
    "    for sample in X:\n",
    "        # Convert each feature to binary (0 or 1) based on threshold\n",
    "        binary_sample = [1 if x > 0.5 else 0 for x in sample[:n_qubits]]\n",
    "        binary_features.append(binary_sample)\n",
    "    return np.array(binary_features)\n",
    "\n",
    "def quantum_feature_mapping(X, n_qubits):\n",
    "    # Prepare binary features for basis embedding\n",
    "    X_binary = prepare_basis_features(X, n_qubits)\n",
    "    \n",
    "    X_quantum = []\n",
    "    for sample in tqdm(X_binary, desc=\"Quantum Feature Mapping\"):\n",
    "        quantum_features = quantum_circuit(sample, n_qubits)\n",
    "        X_quantum.append(quantum_features)\n",
    "    return np.array(X_quantum)\n",
    "\n",
    "def evaluate_classifiers(X_train, X_test, y_train, y_test, classifiers):\n",
    "    results = []\n",
    "    \n",
    "    for name, clf in tqdm(classifiers.items(), desc=\"Training Classifiers\"):\n",
    "        start_fit = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        fit_time = time.time() - start_fit\n",
    "        \n",
    "        start_predict = time.time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        predict_time = time.time() - start_predict\n",
    "        \n",
    "        metrics = {\n",
    "            'Classifier': name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1': f1_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_pred),\n",
    "            'Kappa': cohen_kappa_score(y_test, y_pred),\n",
    "            'Fit Time': fit_time,\n",
    "            'Predict Time': predict_time\n",
    "        }\n",
    "        results.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad16b16-cdeb-4624-99a2-993cabfcd646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "1    255170\n",
      "0     20358\n",
      "Name: count, dtype: int64\n",
      "Balanced class distribution:\n",
      "0    20358\n",
      "1    20358\n",
      "Name: count, dtype: int64\n",
      "Classical ML Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Classifiers: 100%|██████████████████████████████████████████████████████████████| 9/9 [00:47<00:00,  5.23s/it]\n",
      "Quantum Feature Mapping: 100%|███████████████████████████████████████████████████| 32572/32572 [07:08<00:00, 76.00it/s]\n",
      "Quantum Feature Mapping: 100%|█████████████████████████████████████████████████████| 8144/8144 [02:31<00:00, 53.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum ML Evaluation (Basis Embedding):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Classifiers: 100%|██████████████████████████████████████████████████████████████| 9/9 [00:51<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classical ML Results:\n",
      "            Classifier  Accuracy  Precision    Recall        F1   ROC AUC  \\\n",
      "0          Extra Trees  0.999140   0.999026  0.999269  0.999148  0.999139   \n",
      "1              XGBoost  0.999263   0.999513  0.999026  0.999269  0.999265   \n",
      "2        Random Forest  0.999263   1.000000  0.998539  0.999269  0.999269   \n",
      "3             CatBoost  0.999140   0.999756  0.998539  0.999147  0.999146   \n",
      "4             AdaBoost  0.997544   0.998050  0.997077  0.997563  0.997548   \n",
      "5    Gradient Boosting  0.999140   1.000000  0.998295  0.999147  0.999148   \n",
      "6  Logistic Regression  0.978757   0.980689  0.977107  0.978895  0.978771   \n",
      "7                  KNN  0.995825   0.994415  0.997321  0.995866  0.995813   \n",
      "8        Decision Tree  0.998772   0.999025  0.998539  0.998782  0.998774   \n",
      "\n",
      "      Kappa   Fit Time  Predict Time  \n",
      "0  0.998281   2.544776      0.090950  \n",
      "1  0.998526   0.595882      0.011531  \n",
      "2  0.998526   2.639064      0.058283  \n",
      "3  0.998281  17.398735      0.090950  \n",
      "4  0.995088   2.937350      0.109300  \n",
      "5  0.998281  11.808951      0.016384  \n",
      "6  0.957513   0.106392      0.001568  \n",
      "7  0.991650   0.007479      6.859874  \n",
      "8  0.997544   1.160153      0.010906  \n",
      "\n",
      "Quantum ML Results (Basis Embedding):\n",
      "            Classifier  Accuracy  Precision    Recall        F1   ROC AUC  \\\n",
      "0          Extra Trees  0.867387   0.851697  0.892353  0.871551  0.867177   \n",
      "1              XGBoost  0.867387   0.851697  0.892353  0.871551  0.867177   \n",
      "2        Random Forest  0.867387   0.851697  0.892353  0.871551  0.867177   \n",
      "3             CatBoost  0.867387   0.851697  0.892353  0.871551  0.867177   \n",
      "4             AdaBoost  0.845039   0.847677  0.844374  0.846022  0.845045   \n",
      "5    Gradient Boosting  0.867387   0.851697  0.892353  0.871551  0.867177   \n",
      "6  Logistic Regression  0.847495   0.847911  0.849976  0.848942  0.847474   \n",
      "7                  KNN  0.867141   0.851301  0.892353  0.871344  0.866929   \n",
      "8        Decision Tree  0.867387   0.851697  0.892353  0.871551  0.867177   \n",
      "\n",
      "      Kappa   Fit Time  Predict Time  \n",
      "0  0.734649   1.020454      0.081998  \n",
      "1  0.734649   0.552943      0.008772  \n",
      "2  0.734649   1.491264      0.073480  \n",
      "3  0.734649  40.794676      0.056006  \n",
      "4  0.690067   1.178334      0.089668  \n",
      "5  0.734649   1.619382      0.021468  \n",
      "6  0.694963   0.136691      0.001000  \n",
      "7  0.734156   0.058073      3.963885  \n",
      "8  0.734649   0.019016      0.002007  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    X, y = load_and_preprocess('TestbedSunJun13Flows.csv')\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    # Add this after X, y = load_and_preprocess_data('TestbedSunJun13Flows.csv')\n",
    "    # and before train_test_split\n",
    "    \n",
    "    print(\"Original class distribution:\")\n",
    "    print(pd.Series(y).value_counts())\n",
    "    \n",
    "    # Perform undersampling\n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_balanced, y_balanced = undersampler.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Balanced class distribution:\")\n",
    "    print(pd.Series(y_balanced).value_counts())\n",
    "    \n",
    "    # Update your X and y variables\n",
    "    X = X_balanced\n",
    "    y = y_balanced\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    classifiers = {\n",
    "        'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "        'XGBoost': xgb.XGBClassifier(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'CatBoost': CatBoostClassifier(random_state=42, verbose=False),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=42),    \n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    print(\"Classical ML Evaluation:\")\n",
    "    classical_results = evaluate_classifiers(X_train, X_test, y_train, y_test, classifiers)\n",
    "    \n",
    "    # Using 6 qubits for basis embedding (adjust based on quantum hardware constraints)\n",
    "    n_qubits = 8\n",
    "    X_train_quantum = quantum_feature_mapping(X_train, n_qubits)\n",
    "    X_test_quantum = quantum_feature_mapping(X_test, n_qubits)\n",
    "    \n",
    "    print(\"\\nQuantum ML Evaluation (Basis Embedding):\")\n",
    "    quantum_results = evaluate_classifiers(X_train_quantum, X_test_quantum, y_train, y_test, classifiers)\n",
    "    \n",
    "    print(\"\\nClassical ML Results:\")\n",
    "    print(classical_results)\n",
    "    print(\"\\nQuantum ML Results (Basis Embedding):\")\n",
    "    print(quantum_results)\n",
    "\n",
    "    \n",
    "\n",
    "    results_df = pd.DataFrame(quantum_results)\n",
    "    results_df1 = pd.DataFrame(classical_results)\n",
    "    \n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv('5th dataset basis embedding_quantum.csv', index=False)\n",
    "    results_df1.to_csv('5th dataset basis embedding_classical.csv', index=False)\n",
    "\n",
    "   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2470a3-d9be-4043-80b7-6256a637bbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
